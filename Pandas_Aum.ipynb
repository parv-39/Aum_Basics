{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOWmGbYva8C+oHLAOSIaRuo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/parv-39/Aum_Basics/blob/main/Pandas_Aum.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3kNdoOKvd_Df",
        "outputId": "c79c5509-4eae-4ec2-e2f1-5e809d8c0453"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "50\n",
            "8      1/9/2016\n",
            "9     1/10/2016\n",
            "15    1/16/2016\n",
            "26    1/27/2016\n",
            "Name: EST, dtype: object\n",
            "51.67741935483871\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/codebasics/py/refs/heads/master/pandas/1_intro/nyc_weather.csv')\n",
        "\n",
        "a = df['Temperature'].max() #used to find maximum from the dataset\n",
        "b = df['EST'][df['Events']=='Rain'] #used to display the dates on which it was raining\n",
        "c = df['Humidity'].mean() #used to find the average 'Humidity'\n",
        "\n",
        "print(a)\n",
        "print(b)\n",
        "print(c)\n",
        "\n",
        "# print(df)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "input_file = \"https://raw.githubusercontent.com/codebasics/py/refs/heads/master/pandas/1_intro/nyc_weather.csv\"\n",
        "df = pd.read_csv(input_file) #used to access csv file\n",
        "print(df)\n",
        "\n",
        "input_file2 = \"https://github.com/alexsington/Data-Sets/raw/refs/heads/main/nba_player_data.xlsx\"\n",
        "df2 = pd.read_excel(input_file2) #used to access excel file\n",
        "print(df2)\n",
        "\n",
        "details = {\n",
        "    'Names' : ['Parv','Ayush','Hemang','Priyanshu'],\n",
        "    'Birth-dates' : ['12/10/2004','10/4/2004',\"12/10/2001\",\"18/8/2004\"],\n",
        "    'School' : ['RKC','TGES','SOS','SHAKTI'],\n",
        "    'Marks' : [71,78,23,92]\n",
        "}\n",
        "df3 = pd.DataFrame(details) #used to display data from dictionary\n",
        "print(df3)\n",
        "\n",
        "details2 = [\n",
        "    ['Dev','2/9/2004','Rajkot', 46],\n",
        "    ['Harshit','1/4/2004','Porbander', 22],\n",
        "    ['Mustak',\"15/10/2004\",'Rajula', 56],\n",
        "    ['Amaan',\"10/10/2004\",'Rajkot', 67]\n",
        "]\n",
        "df4 = pd.DataFrame(details2,columns=[\"Name\",\"Dates\",\"City\",\"Marks\"]) #used to access data from list\n",
        "print(df4)"
      ],
      "metadata": {
        "id": "IA1V55KZfAl-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "details = {\n",
        "    'Names' : ['Parv','Ayush','Hemang','Priyanshu'],\n",
        "    'Birth-dates' : ['12/10/2004','10/4/2004',\"12/10/2001\",\"18/8/2004\"],\n",
        "    'School' : ['RKC','TGES','SOS','SHAKTI'],\n",
        "    'Marks' : [71,78,23,92]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(details)\n",
        "# print(df)\n",
        "\n",
        "\n",
        "print(df.head(2 )) #used to display the data from starting point\n",
        "print(df.tail(1)) #used to display the data from ending point\n",
        "print(df.columns) #used to  display column names\n",
        "print(df.Names) #used to display the values inside 'Names'\n",
        "print(df['Birth-dates']) #used to display inside 'Birth-dates'\n",
        "print(df[['Names','Birth-dates']]) #used to display specific rows and columns([[]])\n",
        "print(df['Marks'].max()) #find the max marks\n",
        "print(df['Marks'].mean()) #finds the average\n",
        "print(df[df.Marks>=60]) #returns the details regarding the condition\n",
        "print(df.Marks>=60) #returns boolean (True or False)\n",
        "\n",
        "\n",
        "custom_index = pd.RangeIndex(start=0,stop=4,step=1) #for index purpose\n",
        "fd = pd.DataFrame(details,index = custom_index)\n",
        "print(fd)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fsew8k6Wglob",
        "outputId": "606b83ff-35ab-461b-88cb-b076158e6ec7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Names Birth-dates School  Marks\n",
            "0   Parv  12/10/2004    RKC     71\n",
            "1  Ayush   10/4/2004   TGES     78\n",
            "       Names Birth-dates  School  Marks\n",
            "3  Priyanshu   18/8/2004  SHAKTI     92\n",
            "Index(['Names', 'Birth-dates', 'School', 'Marks'], dtype='object')\n",
            "0         Parv\n",
            "1        Ayush\n",
            "2       Hemang\n",
            "3    Priyanshu\n",
            "Name: Names, dtype: object\n",
            "0    12/10/2004\n",
            "1     10/4/2004\n",
            "2    12/10/2001\n",
            "3     18/8/2004\n",
            "Name: Birth-dates, dtype: object\n",
            "       Names Birth-dates\n",
            "0       Parv  12/10/2004\n",
            "1      Ayush   10/4/2004\n",
            "2     Hemang  12/10/2001\n",
            "3  Priyanshu   18/8/2004\n",
            "92\n",
            "66.0\n",
            "       Names Birth-dates  School  Marks\n",
            "0       Parv  12/10/2004     RKC     71\n",
            "1      Ayush   10/4/2004    TGES     78\n",
            "3  Priyanshu   18/8/2004  SHAKTI     92\n",
            "0     True\n",
            "1     True\n",
            "2    False\n",
            "3     True\n",
            "Name: Marks, dtype: bool\n",
            "       Names Birth-dates  School  Marks\n",
            "0       Parv  12/10/2004     RKC     71\n",
            "1      Ayush   10/4/2004    TGES     78\n",
            "2     Hemang  12/10/2001     SOS     23\n",
            "3  Priyanshu   18/8/2004  SHAKTI     92\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"https://raw.githubusercontent.com/codebasics/py/refs/heads/master/pandas/1_intro/nyc_weather.csv\")\n",
        "new_df = df.fillna(0) #used to place \"0\" to the missing data\n",
        "print(new_df)\n",
        "\n",
        "new_df0 = df.fillna(\n",
        "    {\n",
        "        'Temperature' : 0,\n",
        "        'Events' :'no event'\n",
        "    }\n",
        ") #used to add the thd data to the missing values\n",
        "print(new_df0)\n",
        "\n",
        "\n",
        "new_df1 = df.fillna(method=\"ffill\") #it is used to fill the previous data to next missing data\n",
        "print(new_df1)\n",
        "new_df2 = df.fillna(method=\"ffill\",limit = 1) #it is used to fill the previous data to next missing data but the limit is 1\n",
        "print(new_df2)\n",
        "new_df3 = df.fillna(method=\"bfill\") #it is used to fill the next day data to previous missing data\n",
        "print(new_df3)\n",
        "new_df4 = df.fillna(method=\"bfill\",limit = 1) #it is used to fill the next day data to previous missing data nut the limit is 1\n",
        "print(new_df4)\n",
        "\n",
        "# Convert 'EST' column to datetime objects\n",
        "df['EST'] = pd.to_datetime(df['EST'])\n",
        "\n",
        "new_df5 = df.interpolate() #It fills in missing values by guessing what they should be, based on the values before and after them.\n",
        "print(new_df5)\n",
        "new_df6 = df.interpolate(method=\"time\") #It fills in missing values by guessing what they should be, based on the values before and after them.\n",
        "print(new_df6)\n",
        "new_df7 = df.dropna()#used to remove the entire data entry if it contains atleast one missing value\n",
        "print(new_df7)\n",
        "new_df8 = df.dropna(how=\"all\")#used to remove the entire data entry if it contains all missing value\n",
        "print(new_df8)\n",
        "new_df9 = df.dropna(thresh=1)#used to remove the entire data entry if it contains atleast one missing value\n",
        "print(new_df9)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "urs1z8R7g1J3",
        "outputId": "b418b941-2fa4-480e-ecb4-c39b2ace6897"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          EST  Temperature  DewPoint  Humidity  Sea Level PressureIn  \\\n",
            "0    1/1/2016           38        23        52                 30.03   \n",
            "1    1/2/2016           36        18        46                 30.02   \n",
            "2    1/3/2016           40        21        47                 29.86   \n",
            "3    1/4/2016           25         9        44                 30.05   \n",
            "4    1/5/2016           20        -3        41                 30.57   \n",
            "5    1/6/2016           33         4        35                 30.50   \n",
            "6    1/7/2016           39        11        33                 30.28   \n",
            "7    1/8/2016           39        29        64                 30.20   \n",
            "8    1/9/2016           44        38        77                 30.16   \n",
            "9   1/10/2016           50        46        71                 29.59   \n",
            "10  1/11/2016           33         8        37                 29.92   \n",
            "11  1/12/2016           35        15        53                 29.85   \n",
            "12  1/13/2016           26         4        42                 29.94   \n",
            "13  1/14/2016           30        12        47                 29.95   \n",
            "14  1/15/2016           43        31        62                 29.82   \n",
            "15  1/16/2016           47        37        70                 29.52   \n",
            "16  1/17/2016           36        23        66                 29.78   \n",
            "17  1/18/2016           25         6        53                 29.83   \n",
            "18  1/19/2016           22         3        42                 30.03   \n",
            "19  1/20/2016           32        15        49                 30.13   \n",
            "20  1/21/2016           31        11        45                 30.15   \n",
            "21  1/22/2016           26         6        41                 30.21   \n",
            "22  1/23/2016           26        21        78                 29.77   \n",
            "23  1/24/2016           28        11        53                 29.92   \n",
            "24  1/25/2016           34        18        54                 30.25   \n",
            "25  1/26/2016           43        29        56                 30.03   \n",
            "26  1/27/2016           41        22        45                 30.03   \n",
            "27  1/28/2016           37        20        51                 29.90   \n",
            "28  1/29/2016           36        21        50                 29.58   \n",
            "29  1/30/2016           34        16        46                 30.01   \n",
            "30  1/31/2016           46        28        52                 29.90   \n",
            "\n",
            "    VisibilityMiles  WindSpeedMPH PrecipitationIn  CloudCover    Events  \\\n",
            "0                10           8.0               0           5       NaN   \n",
            "1                10           7.0               0           3       NaN   \n",
            "2                10           8.0               0           1       NaN   \n",
            "3                10           9.0               0           3       NaN   \n",
            "4                10           5.0               0           0       NaN   \n",
            "5                10           4.0               0           0       NaN   \n",
            "6                10           2.0               0           3       NaN   \n",
            "7                10           4.0               0           8       NaN   \n",
            "8                 9           8.0               T           8      Rain   \n",
            "9                 4           NaN             1.8           7      Rain   \n",
            "10               10           NaN               0           1       NaN   \n",
            "11               10           6.0               T           4       NaN   \n",
            "12               10          10.0               0           0       NaN   \n",
            "13               10           5.0               T           7       NaN   \n",
            "14                9           5.0               T           2       NaN   \n",
            "15                8           7.0            0.24           7      Rain   \n",
            "16                8           6.0            0.05           6  Fog-Snow   \n",
            "17                9          12.0               T           2      Snow   \n",
            "18               10          11.0               0           1       NaN   \n",
            "19               10           6.0               0           2       NaN   \n",
            "20               10           6.0               0           1       NaN   \n",
            "21                9           NaN            0.01           3      Snow   \n",
            "22                1          16.0            2.31           8  Fog-Snow   \n",
            "23                8           6.0               T           3      Snow   \n",
            "24               10           3.0               0           2       NaN   \n",
            "25               10           7.0               0           2       NaN   \n",
            "26               10           7.0               T           3      Rain   \n",
            "27               10           5.0               0           1       NaN   \n",
            "28               10           8.0               0           4       NaN   \n",
            "29               10           7.0               0           0       NaN   \n",
            "30               10           5.0               0           0       NaN   \n",
            "\n",
            "    WindDirDegrees  \n",
            "0              281  \n",
            "1              275  \n",
            "2              277  \n",
            "3              345  \n",
            "4              333  \n",
            "5              259  \n",
            "6              293  \n",
            "7               79  \n",
            "8               76  \n",
            "9              109  \n",
            "10             289  \n",
            "11             235  \n",
            "12             284  \n",
            "13             266  \n",
            "14             101  \n",
            "15             340  \n",
            "16             345  \n",
            "17             293  \n",
            "18             293  \n",
            "19             302  \n",
            "20             312  \n",
            "21              34  \n",
            "22              42  \n",
            "23             327  \n",
            "24             286  \n",
            "25             244  \n",
            "26             311  \n",
            "27             234  \n",
            "28             298  \n",
            "29             257  \n",
            "30             241  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_excel(\"https://github.com/alexsington/Data-Sets/raw/refs/heads/main/nba_player_data.xlsx\",\"Sheet1\")\n",
        "print(df)\n",
        "\n",
        "\n",
        "\n",
        "df_stocks = pd.DataFrame({\n",
        "    'tickers' : ['GOOGL','WMT','MSFT'],\n",
        "    'price' : [845,65,64],\n",
        "    'pe' : [30.37,14.26,30.97],\n",
        "    'eps' : [27.82,4.61,2.12]\n",
        "})\n",
        "\n",
        "df_weather = pd.DataFrame({\n",
        "    'day' : ['1/1/2017','1/2/2027','1/2/2017'],\n",
        "    'temperature' : [32,35,28],\n",
        "    'event' : ['Rain','Sunny','Snow']\n",
        "})\n",
        "\n",
        "with pd.ExcelWriter('stocks_weather.xlsx') as writer:\n",
        "    df_stocks.to_excel(writer,sheet_name=\"stocks\") #it is used to create an individual sheet in excel\n",
        "    df_weather.to_excel(writer,sheet_name=\"weather\") #it is used to create an individual sheet in excel"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IRqHaSC9hkE6",
        "outputId": "da54fd30-c6e8-493e-a207-8af5493fc098"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         Year       Season_type  PLAYER_ID  RANK           PLAYER TEAM  GP  \\\n",
            "0     2012-13  Regular%20Season     201142     1     Kevin Durant  OKC  81   \n",
            "1     2012-13  Regular%20Season        977     2      Kobe Bryant  LAL  78   \n",
            "2     2012-13  Regular%20Season       2544     3     LeBron James  MIA  76   \n",
            "3     2012-13  Regular%20Season     201935     4     James Harden  HOU  78   \n",
            "4     2012-13  Regular%20Season       2546     5  Carmelo Anthony  NYK  67   \n",
            "...       ...               ...        ...   ...              ...  ...  ..   \n",
            "7288  2021-22          Playoffs    1629006   206      Josh Okogie  MIN   1   \n",
            "7289  2021-22          Playoffs    1630556   206  Kessler Edwards  BKN   2   \n",
            "7290  2021-22          Playoffs    1630201   206    Malachi Flynn  TOR   6   \n",
            "7291  2021-22          Playoffs     202693   206  Markieff Morris  MIA   2   \n",
            "7292  2021-22          Playoffs     200794   206     Paul Millsap  PHI   1   \n",
            "\n",
            "       MIN  FGM   FGA  ...  REB  AST  STL  BLK  TOV   PF   PTS   EFF  AST_TOV  \\\n",
            "0     3119  731  1433  ...  640  374  116  105  280  143  2280  2462     1.34   \n",
            "1     3013  738  1595  ...  433  469  106   25  287  173  2133  1921     1.63   \n",
            "2     2877  765  1354  ...  610  551  129   67  226  110  2036  2446     2.44   \n",
            "3     2985  585  1337  ...  379  455  142   38  295  178  2023  1872     1.54   \n",
            "4     2482  669  1489  ...  460  171   52   32  175  205  1920  1553     0.98   \n",
            "...    ...  ...   ...  ...  ...  ...  ...  ...  ...  ...   ...   ...      ...   \n",
            "7288     2    0     0  ...    0    0    0    0    0    0     0     0     0.00   \n",
            "7289     7    0     0  ...    0    1    1    0    1    3     0     1     1.00   \n",
            "7290    36    0     7  ...    3    3    1    0    1    6     0    -1     3.00   \n",
            "7291     3    0     1  ...    1    0    0    0    1    2     0    -1     0.00   \n",
            "7292     6    0     0  ...    1    1    0    0    0    1     0     2     0.00   \n",
            "\n",
            "      STL_TOV  \n",
            "0        0.41  \n",
            "1        0.37  \n",
            "2        0.57  \n",
            "3        0.48  \n",
            "4        0.30  \n",
            "...       ...  \n",
            "7288     0.00  \n",
            "7289     1.00  \n",
            "7290     1.00  \n",
            "7291     0.00  \n",
            "7292     0.00  \n",
            "\n",
            "[7293 rows x 29 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"https://raw.githubusercontent.com/codebasics/py/refs/heads/master/pandas/1_intro/nyc_weather.csv\")\n",
        "df.fillna(\"NaN\",inplace = True) #used to add \"NaN\" to missing values\n",
        "# df = pd.read_csv(\"C:/extra/random/Pandas/nyc_weather.csv\",nrows=3) #used to print data atmost to 3\n",
        "# df.to_csv(\"my_new2.csv\",index = False) #used to create new csv file\n",
        "print(df.columns ) #used to display all the columns of the dataset\n",
        "df.to_csv(\"3_columns.csv\",columns = ['EST','Temperature','Events']) #used to create new csv file and add data of the particular columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6cD3JOQNiaG6",
        "outputId": "b3b59bbe-4e20-493a-c2b6-a27d2bdb9990"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['EST', 'Temperature', 'DewPoint', 'Humidity', 'Sea Level PressureIn',\n",
            "       'VisibilityMiles', 'WindSpeedMPH', 'PrecipitationIn', 'CloudCover',\n",
            "       'Events', 'WindDirDegrees'],\n",
            "      dtype='object')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-131508936.py:3: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'NaN' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
            "  df.fillna(\"NaN\",inplace = True) #used to add \"NaN\" to missing values\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "details = {\n",
        "    'Names' : ['Parv','Ayush','Hemang','Priyanshu','Bhargav'],\n",
        "    'Birth-dates' : ['12/10/2004','10/4/2004',\"12/10/2001\",\"18/8/2004\",\"23/2/2005\"],\n",
        "    'School' : ['RKC','TGES','SOS','SHAKTI',\"New Parimal\"],\n",
        "    'Marks' : [71,\"78F\",\"23F\",\"91F\",99]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(details)\n",
        "# print(df)\n",
        "\n",
        "# new_df = df.replace(0,np.nan) #used to replace the value\n",
        "# print(new_df)\n",
        "\n",
        "new_df2 = df.replace({ #used to replace particular element with data\n",
        "     99 : 15,\n",
        "    'New Parimal' : 'New Parimal School'\n",
        "})\n",
        "print(new_df2)\n",
        "\n",
        "new_df3 = df.replace({ #used to remove certain part of the value and and of specified amount\n",
        "    'Marks': '[A-Za-z]'\n",
        "},'',regex = True)\n",
        "\n",
        "print(new_df3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W5BX5kn0iuTf",
        "outputId": "e8f638b7-d55a-4f0b-ae78-5c4d96f84a37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       Names Birth-dates              School Marks\n",
            "0       Parv  12/10/2004                 RKC    71\n",
            "1      Ayush   10/4/2004                TGES   78F\n",
            "2     Hemang  12/10/2001                 SOS   23F\n",
            "3  Priyanshu   18/8/2004              SHAKTI   91F\n",
            "4    Bhargav   23/2/2005  New Parimal School    15\n",
            "       Names Birth-dates       School Marks\n",
            "0       Parv  12/10/2004          RKC    71\n",
            "1      Ayush   10/4/2004         TGES    78\n",
            "2     Hemang  12/10/2001          SOS    23\n",
            "3  Priyanshu   18/8/2004       SHAKTI    91\n",
            "4    Bhargav   23/2/2005  New Parimal    99\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "details = {\n",
        "    'Names' : ['Parv','Ayush','Hemang','Priyanshu','Bhargav'],\n",
        "    'Birth-dates' : ['12/10/2004','10/4/2004',\"12/10/2001\",\"18/8/2004\",\"23/2/2005\"],\n",
        "    'School' : ['RKC','TGES','SOS','SHAKTI',\"New Parimal\"],\n",
        "    'Marks' : [71,\"78F\",\"23F\",\"91F\",99],\n",
        "    'City' : ['Rajkot','Mumbai','Rajkot','Ahmedabad','Ahmedabad']\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(details)\n",
        "# print(df)\n",
        "\n",
        "g = df.groupby('City') #used to group data by city\n",
        "# print(g)\n",
        "for city,city_df in g: #used to display the city and city_df\n",
        "    print(city)\n",
        "    print(city_df)\n",
        "\n",
        "g.get_group('Mumbai')\n",
        "# g.discribe() #used to print all the math operations(mean,max,min,std,etc...)\n",
        "# print(g)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 271
        },
        "id": "SH6oMST1tvSI",
        "outputId": "eef9cbcf-45df-4b97-cb47-e6c1b03f8701"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ahmedabad\n",
            "       Names Birth-dates       School Marks       City\n",
            "3  Priyanshu   18/8/2004       SHAKTI   91F  Ahmedabad\n",
            "4    Bhargav   23/2/2005  New Parimal    99  Ahmedabad\n",
            "Mumbai\n",
            "   Names Birth-dates School Marks    City\n",
            "1  Ayush   10/4/2004   TGES   78F  Mumbai\n",
            "Rajkot\n",
            "    Names Birth-dates School Marks    City\n",
            "0    Parv  12/10/2004    RKC    71  Rajkot\n",
            "2  Hemang  12/10/2001    SOS   23F  Rajkot\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Names Birth-dates School Marks    City\n",
              "1  Ayush   10/4/2004   TGES   78F  Mumbai"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-be39ef35-958c-491f-aec2-3114559843e2\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Names</th>\n",
              "      <th>Birth-dates</th>\n",
              "      <th>School</th>\n",
              "      <th>Marks</th>\n",
              "      <th>City</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Ayush</td>\n",
              "      <td>10/4/2004</td>\n",
              "      <td>TGES</td>\n",
              "      <td>78F</td>\n",
              "      <td>Mumbai</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-be39ef35-958c-491f-aec2-3114559843e2')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-be39ef35-958c-491f-aec2-3114559843e2 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-be39ef35-958c-491f-aec2-3114559843e2');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "repr_error": "0"
            }
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "details1 = {\n",
        "    'Names' : ['Parv','Ayush','Hemang','Priyanshu','Bhargav'],\n",
        "    'Birth-dates' : ['12/10/2004','10/4/2004',\"12/10/2001\",\"18/8/2004\",\"23/2/2005\"],\n",
        "    'School' : ['RKC','TGES','SOS','SHAKTI',\"New Parimal\"],\n",
        "    'Marks' : [71,78,23,9,99],\n",
        "    'City' : ['Rajkot','Mumbai','Rajkot','Ahmedabad','Ahmedabad']\n",
        "}\n",
        "\n",
        "details2 = {\n",
        "    'Names' : ['Purva','Ayushi','Hemangi','Priyanshi','Shuchi'],\n",
        "    'Birth-dates' : ['2/11/2004','1/6/2003',\"12/1/2001\",\"18/9/2008\",\"23/2/2005\"],\n",
        "    'School' : ['Rk','SNK','KY','SHAKTI',\"New Parimal\"],\n",
        "    'Marks' : [71,89,56,55,100],\n",
        "    'City' : ['Rajkot','Mumbai','Rajkot','Ahmedabad','Ahmedabad']\n",
        "}\n",
        "\n",
        "df1 = pd.DataFrame(details1)\n",
        "df2 = pd.DataFrame(details2)\n",
        "\n",
        "# df3 = pd.merge(df1,df2,on = \"Names\",how = \"outer\") #used to merge to dataset together (\"outer = Union\" and \"inner = Intersection[default]\",right,left)\n",
        "# df4 = pd.merge(df1,df2,on = \"Names\",how = \"outer\",indicator = True) #display the data that it caame form which dataset(left or right)\n",
        "# print(df3)\n",
        "# print(df4)\n",
        "\n",
        "df5 = pd.merge(df1,df2,on = \"Names\",how = \"outer\",suffixes = (\"_left\",\"_right\")) #suffixes indicates the name of both the name of dataset\n",
        "print(df5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lwaJGrAjyeB7",
        "outputId": "409e6404-30ba-492a-caea-63792e77cd27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       Names Birth-dates_left  School_left  Marks_left  City_left  \\\n",
            "0      Ayush        10/4/2004         TGES        78.0     Mumbai   \n",
            "1     Ayushi              NaN          NaN         NaN        NaN   \n",
            "2    Bhargav        23/2/2005  New Parimal        99.0  Ahmedabad   \n",
            "3     Hemang       12/10/2001          SOS        23.0     Rajkot   \n",
            "4    Hemangi              NaN          NaN         NaN        NaN   \n",
            "5       Parv       12/10/2004          RKC        71.0     Rajkot   \n",
            "6  Priyanshi              NaN          NaN         NaN        NaN   \n",
            "7  Priyanshu        18/8/2004       SHAKTI         9.0  Ahmedabad   \n",
            "8      Purva              NaN          NaN         NaN        NaN   \n",
            "9     Shuchi              NaN          NaN         NaN        NaN   \n",
            "\n",
            "  Birth-dates_right School_right  Marks_right City_right  \n",
            "0               NaN          NaN          NaN        NaN  \n",
            "1          1/6/2003          SNK         89.0     Mumbai  \n",
            "2               NaN          NaN          NaN        NaN  \n",
            "3               NaN          NaN          NaN        NaN  \n",
            "4         12/1/2001           KY         56.0     Rajkot  \n",
            "5               NaN          NaN          NaN        NaN  \n",
            "6         18/9/2008       SHAKTI         55.0  Ahmedabad  \n",
            "7               NaN          NaN          NaN        NaN  \n",
            "8         2/11/2004           Rk         71.0     Rajkot  \n",
            "9         23/2/2005  New Parimal        100.0  Ahmedabad  \n"
          ]
        }
      ]
    }
  ]
}